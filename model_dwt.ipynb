{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb6a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import psutil\n",
    "import torch\n",
    "#print(psutil.virtual_memory())\n",
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c5e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21b3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### building the model architecture\n",
    "\n",
    "#### 2d dwt transform operation \n",
    "def dwt(x) :\n",
    "    \n",
    "    x01 = x[:,:,0::2,:]/2\n",
    "    x02 = x[:,:,1::2,:]/2\n",
    "    x1 = x01[:,:,:,0::2]\n",
    "    x2 = x01[:,:,:,1::2]\n",
    "    x3 = x02[:,:,:,0::2]\n",
    "    x4 = x02[:,:,:,1::2]\n",
    "    x_LL = x1 + x2 + x3 + x4\n",
    "    x_LH = -x1 -x2 + x3 + x4\n",
    "    x_HL = -x1 + x2 -x3 + x4\n",
    "    x_HH = x1 -x2 -x3 + x4\n",
    "    return x_LL,torch.cat([x_LH,x_HL,x_HH],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc578e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DWT modules \n",
    "class DWT(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.requires_grad = False \n",
    "    def forward(self,x) :\n",
    "        return dwt(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "                                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfc5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWT_down(nn.Module) :\n",
    "    def __init__(self,in_c,out_c) :\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size = 4 ,stride = 2, padding = 1,bias = True),\n",
    "                                        nn.BatchNorm2d(out_c),\n",
    "                                        nn.LeakyReLU(0.2,inplace = True)\n",
    "        )\n",
    "    def forward(self,x)  :\n",
    "        x = self.conv_block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b232f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWT_up(nn.Module)   :\n",
    "    def __init__(self,in_c,out_c) :\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.ConvTranspose2d(in_c,out_c,kernel_size = 4 ,stride = 2 , padding = 1,bias = True),\n",
    "                                        nn.BatchNorm2d(out_c),\n",
    "                                        nn.ReLU()\n",
    "                                       )\n",
    "    def  forward(self,x)    :\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4baba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DWT Module\n",
    "class DWT_up_bottom(nn.Module) :\n",
    "    def __init__(self,in_c,out_c) :\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.ConvTranspose2d(in_c,out_c,kernel_size = 3,stride = 1 , padding = 1,bias = True),\n",
    "                                        nn.BatchNorm2d(out_c),\n",
    "                                        nn.ReLU()\n",
    "                                       )\n",
    "    def  forward(self,x)    :\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d6cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initial and dwt 1x1 convolution blocks\n",
    "class init_conv(nn.Module) :\n",
    "    def __init__(self,in_c,out_c) :\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size =  3,stride = 1, padding = 1),\n",
    "                                        nn.BatchNorm2d(out_c),\n",
    "                                        nn.LeakyReLU(0.2,inplace = True)\n",
    "        )\n",
    "    def forward(self,x)  :\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9186ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_1x1_down(nn.Module) :\n",
    "    def __init__(self,in_c,out_c ):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size = 1,stride = 1,padding = 0))\n",
    "                 \n",
    "    def forward(self,x) :\n",
    "        \n",
    "        x = self.conv_block(x) \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1573e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_1x1_up(nn.Module) :\n",
    "    def __init__(self,in_c,out_c) :\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(nn.Conv2d(in_c,out_c,kernel_size = 1,stride = 1,padding = 0),\n",
    "                                       nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True))\n",
    "    def forward(self,x)   :\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2677a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special(x) :\n",
    "    for  i in range(31) :\n",
    "        x = torch.cat([x,x],1)\n",
    "    return  x    \n",
    "        \n",
    "    \n",
    "class special_block(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.requires_grad = False\n",
    "    def forward(self,x) :\n",
    "        return special(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a805cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### architecture of the model\n",
    "class model_image_reconst(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.first = init_conv(1,32)\n",
    "        self.DWT = DWT()\n",
    "        self.down1 = DWT_down(32,64)\n",
    "        self.down2 = DWT_down(128,128)\n",
    "        self.down3 = DWT_down(256,256)\n",
    "        self.second = init_conv(512,512)\n",
    "        self.bottom = DWT_up_bottom(512,512)\n",
    "        self.up1 = DWT_up(1024,256)\n",
    "        self.up2 = DWT_up(768,128)\n",
    "        self.up3 = DWT_up(384,64)\n",
    "        self.third = init_conv(512,512)\n",
    "        self.down_low_f1 = conv_1x1_down(32,64)\n",
    "        self.down_low_f2 = conv_1x1_down(128,128)\n",
    "        self.down_low_f3 = conv_1x1_down(256,256)\n",
    "        self.up_high_f3 = conv_1x1_up(3*256,256)\n",
    "        self.up_high_f2 = conv_1x1_up(3*128,128)\n",
    "        self.up_high_f1 = conv_1x1_up(3*32,64)\n",
    "        self.zero_pad = nn.ZeroPad2d(2)\n",
    "        \n",
    "        self.tail_0 = nn.Sequential(nn.Conv2d(128,32,kernel_size = 5 , stride  = 1,padding =0),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.tail_1 = nn.Sequential(nn.Conv2d(64,32,kernel_size = 3 , stride  = 1,padding =1),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.tail_01 = nn.Sequential(nn.Conv2d(32,32,kernel_size = 3 , stride  = 1,padding =1),\n",
    "                                   #nn.BatchNorm2d(32)\n",
    "                                   nn.ReLU())\n",
    "        self.tail_2 = nn.Conv2d(32,1,kernel_size = 3, stride = 1,padding  = 1)\n",
    "        self.conv_13 = nn.ConvTranspose2d(256,256,kernel_size = 3, stride  = 1, padding  = 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.last = nn.Sequential(nn.Conv2d(2,1,kernel_size = 1,stride =1 ,padding = 0),nn.ReLU())\n",
    "        self.special = special_block()\n",
    "        \n",
    "    def forward(self,x)  :\n",
    "        \n",
    "        x_1 = self.first(x)\n",
    "        x1 = self.zero_pad(x_1)\n",
    "        \n",
    "        low_f1 ,high_f1 = self.DWT(x1)\n",
    "        \n",
    "        low_f1 = self.down_low_f1(low_f1)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        \n",
    "        x2 = torch.cat([x2,low_f1],1)\n",
    "        \n",
    "        low_f2,high_f2 = self.DWT(x2)\n",
    "        low_f2 = self.down_low_f2(low_f2)\n",
    "        x3 = self.down2(x2)\n",
    "        x3 = torch.cat([x3,low_f2],1)\n",
    "        #print(x3.shape)\n",
    "        low_f3,high_f3 = self.DWT(x3)\n",
    "        \n",
    "        low_f3 = self.down_low_f3(low_f3)\n",
    "        x4 = self.down3(x3)\n",
    "        x4 = torch.cat([x4,low_f3],1)\n",
    "        x5 = self.second(x4)\n",
    "        y0 = self.bottom(x5)\n",
    "        y0 = torch.cat([y0,x4],1)\n",
    "        y1 = self.up1(y0)\n",
    "        high_f3 = self.up_high_f3(high_f3)\n",
    "        high_f3 = self.conv_13(high_f3)\n",
    "        y1 = torch.cat([y1,high_f3,x3],1)\n",
    "        y2 = self.up2(y1)\n",
    "        high_f2 = self.up_high_f2(high_f2)\n",
    "        y2 = torch.cat([y2,high_f2,x2],1)\n",
    "        y3 = self.up3(y2)\n",
    "        high_f1 = self.up_high_f1(high_f1)\n",
    "        y3 = torch.cat([y3,high_f1],1)\n",
    "        #print(y3.shape)\n",
    "        y4 = self.tail_0(y3)\n",
    "        #print(y4.shap(e)\n",
    "        y4 = torch.cat([y4 , x_1],1)\n",
    "        y5 = self.tail_1(y4)\n",
    "        \n",
    "        \n",
    "        y6 = self.tail_01(y5)\n",
    "        out = self.tail_2(y6)\n",
    "        out = torch.cat([out,x],1)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901440e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\" :\n",
    "#    x = torch.rand((32,1,100,100))\n",
    "#    model = model_image_reconst()\n",
    "#    y = model(x)\n",
    "#    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22ff28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### loading the data set\n",
    "from  glob import glob\n",
    "import os\n",
    "train_x = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/train/images/*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7352b276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0001.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0002.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0003.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0004.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0005.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0006.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0007.png']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth/*\"))\n",
    "train_y[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c18fc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_y = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/test/grdtruth/*\"))\n",
    "test_x = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/test/images/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b197e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### dataloader \n",
    "from PIL import Image ,ImageOps\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "class DWT_dataset(Dataset) :\n",
    "    def __init__(self,image_path,gtr_path) :\n",
    "        self.image_path = image_path\n",
    "        self.gtr_path = gtr_path\n",
    "    def __len__(self)    :\n",
    "        return len(self.image_path)\n",
    "    def __getitem__(self,idx) :\n",
    "        image = Image.open(self.image_path[idx])\n",
    "    \n",
    "        image = np.expand_dims(image,axis = 0)\n",
    "        image = image.astype(np.float32)\n",
    "        image = image\n",
    "        image = torch.from_numpy(image)\n",
    "        gtr = Image.open(self.gtr_path[idx])\n",
    "        gtr = np.expand_dims(gtr,axis = 0)\n",
    "        gtr = gtr.astype(np.float32)\n",
    "        gtr = gtr\n",
    "        gtr = torch.from_numpy(gtr)\n",
    "        return image, gtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "263baaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/Pawan/Documents/pavan_data_500/train/images\\\\train_0006.png',\n",
       " 'C:/Users/Pawan/Documents/pavan_data_500/train/grdtruth\\\\gtruth_0006.png')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### creation of dataset\n",
    "\n",
    "train_dataset = DWT_dataset(train_x,train_y)\n",
    "test_dataset = DWT_dataset(test_x,test_y)\n",
    "\n",
    "train_x[5],train_y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93c99204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### dataloader\n",
    "epochs = 25\n",
    "batch_size = 40\n",
    "train_loader = DataLoader(dataset = train_dataset,batch_size = batch_size)\n",
    "\n",
    "len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee6e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset = test_dataset,shuffle = False,batch_size = batch_size )\n",
    "device = 'cuda' \n",
    "loss_fn = nn.L1Loss()\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7af9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_image_reconst()\n",
    "model1 = model1.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e626b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def seeding(seed) :\n",
    "  random.seed(seed)\n",
    "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3b81d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model1.parameters(),lr,betas =( 0.5,0.8),weight_decay = 0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min',patience = 5,verbose = True)\n",
    "model_params_path = \"C:/Users/Pawan/Documents/pavan_data_500/model_parameters.pth\"\n",
    "model_params_trainpath = \"C:/Users/Pawan/Documents/pavan_data_500/model_parameters1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f5cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### training and validating\n",
    "def train(model,loader,optimizer,loss_fn,device) :\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    for x,y in loader:\n",
    "        \n",
    "        x = x.to(device,dtype = torch.float32)\n",
    "        y = y.to(device,dtype = torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss = epoch_loss/len(loader)     \n",
    "    return epoch_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9583a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### evaluating\n",
    "def evaluate(model,loader,loss_fn,device):\n",
    "    epoch_loss = 0.0 \n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        for x,y in loader :\n",
    "            x = x.to(device,dtype = torch.float32)\n",
    "            y = y.to(device,dtype = torch.float32)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            epoch_loss += loss.item()\n",
    "    epoch_loss = epoch_loss/len(loader)   \n",
    "    \n",
    "    return epoch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "528cbd7d-7316-44e9-8d42-c72d2324635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/valid/grdtruth/*\"))\n",
    "valid_x = sorted(glob(\"C:/Users/Pawan/Documents/pavan_data_500/valid/images/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43194818-1a50-4071-ac29-04258980994d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740d210-acf3-4870-b63e-99c9083fb10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd00346-4573-47ec-bd52-8cb68389ba23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a798ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  :  1|| trainloss : 2.023793349947248  || validloss : 2.0143544673919678 \n",
      "epoch  :  2|| trainloss : 2.0244430417106267  || validloss : 2.544014835357666 \n",
      "epoch  :  3|| trainloss : 2.1048871710186914  || validloss : 3.043091058731079 \n",
      "epoch  :  4|| trainloss : 2.0816804602032617  || validloss : 1.9969649076461793 \n",
      "epoch  :  5|| trainloss : 1.945006683894566  || validloss : 2.422507905960083 \n",
      "epoch  :  6|| trainloss : 2.0295566808609737  || validloss : 3.0706061363220214 \n",
      "epoch  :  7|| trainloss : 1.8670977444875807  || validloss : 2.427047300338745 \n",
      "epoch  :  8|| trainloss : 1.8390808116822015  || validloss : 2.474214029312134 \n",
      "epoch  :  9|| trainloss : 1.8318489528837658  || validloss : 4.309624767303466 \n",
      "epoch  :  10|| trainloss : 1.890317379860651  || validloss : 3.119717741012573 \n",
      "epoch  :  11|| trainloss : 1.77223120984577  || validloss : 1.9651941299438476 \n",
      "epoch  :  12|| trainloss : 1.7689502341406687  || validloss : 1.9792104721069337 \n",
      "epoch  :  13|| trainloss : 1.763067863101051  || validloss : 2.6086219787597655 \n",
      "epoch  :  14|| trainloss : 1.8264753614153182  || validloss : 1.9196135520935058 \n",
      "epoch  :  15|| trainloss : 1.7909533852622623  || validloss : 3.783579444885254 \n",
      "epoch  :  16|| trainloss : 1.8815863904498873  || validloss : 4.148956775665283 \n",
      "epoch  :  17|| trainloss : 1.810494497844151  || validloss : 3.9479724884033205 \n",
      "epoch  :  18|| trainloss : 1.729112111954462  || validloss : 3.5355503082275392 \n",
      "epoch  :  19|| trainloss : 1.7783207337061564  || validloss : 2.3074671745300295 \n",
      "epoch  :  20|| trainloss : 1.7268303144545782  || validloss : 2.87937970161438 \n",
      "epoch  :  21|| trainloss : 1.7821295420328775  || validloss : 2.9285141944885256 \n",
      "epoch  :  22|| trainloss : 1.8328135944548107  || validloss : 3.173211193084717 \n",
      "epoch  :  23|| trainloss : 1.7314266341073172  || validloss : 1.9077354192733764 \n",
      "epoch  :  24|| trainloss : 1.7991022007805961  || validloss : 3.272757911682129 \n",
      "epoch  :  25|| trainloss : 1.818006604058402  || validloss : 1.9955650806427 \n"
     ]
    }
   ],
   "source": [
    "##### training the model\n",
    "best_valid_loss = float('inf')\n",
    "best_train_loss = float('inf')\n",
    "seeding(42)\n",
    "for epoch in range(epochs) :\n",
    "    train_loss = train(model1,train_loader,optimizer,loss_fn,device)\n",
    "    valid_loss = evaluate(model1,test_loader,loss_fn,device)\n",
    "    if valid_loss < best_valid_loss :\n",
    "        torch.save(model1.state_dict(),model_params_path)\n",
    "        best_valid_loss = valid_loss\n",
    "    if train_loss < best_train_loss :\n",
    "        torch.save(model1.state_dict(),model_params_trainpath)\n",
    "        best_train_loss = train_loss    \n",
    "    print(f\"epoch  : {epoch+1 : 02}|| trainloss : {train_loss}  || validloss : {valid_loss} \")    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1974f3b-a13e-46c4-a1e6-580405b8692c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_n \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43my\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      3\u001b[0m y_n \u001b[38;5;241m=\u001b[39m y_n[\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m,:,:]\n\u001b[0;32m      4\u001b[0m y_pred_n \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_pred\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "y_n = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "y_n = y_n[None,None,:,:]\n",
    "y_pred_n = torch.from_numpy(y_pred.astype(np.float32))\n",
    "y_pred_n = y_pred_n[None,None,:,:]\n",
    "\n",
    "import math\n",
    "from math import exp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def ssim(img1, img2, window_size=11, sigma=1.5):\n",
    "    # Ensure inputs are in the range [0, 1]\n",
    "    img1 = torch.clamp(img1, 0, 1)\n",
    "    img2 = torch.clamp(img2, 0, 1)\n",
    "\n",
    "    # Create a Gaussian window\n",
    "    window = torch.tensor(\n",
    "        [[exp(-0.5 * ((i - window_size // 2) / sigma)**2 - 0.5 * ((j - window_size // 2) / sigma)**2)\n",
    "          for j in range(window_size)]\n",
    "         for i in range(window_size)]\n",
    "    ).unsqueeze(0).unsqueeze(0).to(img1.device, dtype=img1.dtype)\n",
    "    window = window / window.sum()\n",
    "\n",
    "    # Compute mean of both images\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2)\n",
    "\n",
    "    # Compute variance and covariance\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2) - mu1_mu2\n",
    "\n",
    "    # Compute SSIM\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    # Compute mean SSIM over the image\n",
    "    ssim_index = torch.mean(ssim_map)\n",
    "\n",
    "    return ssim_index\n",
    "\n",
    "# Example usage\n",
    "img1 = torch.rand(1, 1, 100, 100)  # Example grayscale image\n",
    "img2 = torch.rand(1, 1, 100, 100)  # Example grayscale image\n",
    "\n",
    "ssim_value = ssim(y_n,y_pred_n)\n",
    "print(\"SSIM:\", ssim_value.item())\n",
    "\n",
    "\n",
    "y_n.dtype\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b9e8e45-9ef8-42bd-a49a-d52072c75ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing\n",
    "\n",
    "x_path = valid_x[4]\n",
    "x =np.array(Image.open(x_path))\n",
    "y_path = valid_y[4]\n",
    "y = np.array(Image.open(y_path))\n",
    "type(x)\n",
    "#plt.subplot(1,3,1)\n",
    "#plt.imshow(x,cmap = 'gray')\n",
    "#plt.subplot(1,3,2)\n",
    "with torch.no_grad() :\n",
    "    \n",
    "    model = model_image_reconst()\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    x = torch.from_numpy(x)\n",
    "    x =  x[None,None,:,:]\n",
    "    x = x.to(device,dtype = torch.float32)\n",
    "    model.load_state_dict(torch.load(model_params_trainpath,map_location = device))\n",
    "    y_pred = model(x)\n",
    "    #x = torch.squeeze(x,dim = 0)\n",
    "    #x = torch.squeeze(x,dim = 0)\n",
    "    #x = x.cpu().numpy()\n",
    "    \n",
    "    y_pred = torch.squeeze(y_pred ,dim = 0)\n",
    "    y_pred = torch.squeeze(y_pred ,dim = 0)\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    out = Image.fromarray(y_pred)\n",
    "    image_rgb = out.convert('RGB')\n",
    "    image_rgb.save('Valid_4.png')\n",
    "    out.show()\n",
    "    #y_pred = np.array(y_pred,dtype =np.uint8)\n",
    "    #y_pred = y_pred\n",
    "    \n",
    "   # plt.imshow(y_pred, cmap = 'gray')\n",
    "    \n",
    "  #  plt.subplot(1,3,3)\n",
    "    #plt.imshow(y_pred, cmap = 'gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0006d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "image_path = \"C:/Users/Pawan/Documents/PAVAN (MTECH 22EE65R07)/MTP/pavan/mono.jpg\"\n",
    "mpimag_ = mpimg.imread(image_path)\n",
    "#plt.imshow(mpimag_[750:1250,750:1250])\n",
    "image = Image.open(image_path)\n",
    "image_ = ImageOps.grayscale(image)\n",
    "image__ = np.array(image_,dtype = np.float32)\n",
    "\n",
    "imag = image__[500:1000,500:1000]\n",
    "imag_ = Image.fromarray(imag)\n",
    "imag_ = imag_.resize((100,100))\n",
    "#imag_ = np.array(imag_,dtype = np.float32)\n",
    "image__rgb = imag_.convert('RGB')\n",
    "image__rgb.save('original.png')\n",
    "\n",
    "imag_.show()\n",
    "#plt.imshow(imag_,cmap = 'summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a7ec375",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad() :\n",
    "    \n",
    "    model = model_image_reconst()\n",
    "    model = model.to(device)\n",
    "    imag = torch.from_numpy(np.array(imag_,dtype =np.float32))\n",
    "    imag =  imag[None,None,:,:]\n",
    "    imag = imag.to(device,dtype = torch.float32)\n",
    "    model.load_state_dict(torch.load(model_params_trainpath,map_location = device))\n",
    "    \n",
    "    y_pred = model(imag)\n",
    "    #x = torch.squeeze(x,dim = 0)\n",
    "    #x = torch.squeeze(x,dim = 0)\n",
    "    #x = x.cpu().numpy()\n",
    "    \n",
    "    y_pred = torch.squeeze(y_pred ,dim = 0)\n",
    "    y_pred = torch.squeeze(y_pred ,dim = 0)\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    #y_pred = np.array(y_pred,dtype =np.uint8)\n",
    "    #y_pred = y_pred\n",
    "    out = Image.fromarray(y_pred)\n",
    "    image_rgb = out.convert('RGB')\n",
    "    image_rgb.save('result.png')\n",
    "    out.show()\n",
    "    \n",
    "    #plt.imshow(y_pred, cmap = 'summer')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d22aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6964acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600d5ad-1505-449f-b1a6-eb4ae8fa0a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9ffd7-f297-4998-83b1-a73323ed77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb0960-da9c-44c6-b109-b504db46f959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50269b-2803-4b21-932a-8f2630d27e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bb5d0-aec6-44f7-a474-069c7d71c46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43e10b-7be8-469d-a3e5-78102a9b3d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
